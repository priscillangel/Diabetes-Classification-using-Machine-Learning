{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudhandar/ResNet-50-model/blob/master/resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-MveCUEP1Ms",
        "outputId": "e58ee8fd-8b54-4037-e70e-935235fd31eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "XlVyLK0Rgqe6",
        "outputId": "bbdc5349-cd8c-4179-f42e-af1d9392b8ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2372646b-1243-4f3e-ba0b-9b908551f54e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2372646b-1243-4f3e-ba0b-9b908551f54e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload kaggle.json file downloaded from Kaggle account\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded file to the required directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6-U8MgvhR0W",
        "outputId": "8b333263-650f-4a3e-a98b-a0bb204d0f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "alzheimer-mri-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d sachinkumar413/alzheimer-mri-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvw7AyFZhbCh",
        "outputId": "ca3b8e82-ea7f-4f33-fc0a-107a2fcc3927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace data_folder/Dataset/Mild_Demented/mild.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!unzip -q alzheimer-mri-dataset -d data_folder\n",
        "\n",
        "# Define data directory after extraction\n",
        "data_dir = '/content/data_folder/Dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJW4NkrvP_Gd",
        "outputId": "b3702c36-4d24-4e4b-a588-dbde046c9999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6400 files belonging to 4 classes.\n",
            "Using 5120 files for training.\n",
            "Found 6400 files belonging to 4 classes.\n",
            "Using 1280 files for validation.\n",
            "(32, 64, 64, 3)\n",
            "[3 3 2 2 2 2 2 3 3 3 2 2 3 2 1 2 0 2 2 2 0 2 3 0 3 2 2 2 2 3 0 2]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import math\n",
        "# ------------------------------------- #\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def load_dataset(data_dir, image_size, batch_size):\n",
        "    train_ds = image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    val_ds = image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    classes = train_ds.class_names\n",
        "    return train_ds, val_ds, classes\n",
        "\n",
        "def preprocess_data(train_ds, val_ds, image_size, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    normalization_layer = layers.Rescaling(1./255)\n",
        "    augmented_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    augmented_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "    return augmented_train_ds, augmented_val_ds\n",
        "\n",
        "# Define parameters\n",
        "data_dir = '/content/data_folder/Dataset'\n",
        "image_size = (64, 64)\n",
        "batch_size = 32\n",
        "\n",
        "# Load dataset\n",
        "train_ds, val_ds, classes = load_dataset(data_dir, image_size, batch_size)\n",
        "\n",
        "# Preprocess data\n",
        "train_ds, val_ds = preprocess_data(train_ds, val_ds, image_size, batch_size)\n",
        "\n",
        "# Example usage\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(images.shape)  # Shape of the batch of images\n",
        "    print(labels.numpy())  # Labels corresponding to the images\n",
        "\n",
        "\n",
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0]\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Shuffle\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation,:,:,:]\n",
        "    shuffled_Y = Y[permutation,:]\n",
        "\n",
        "    # Partition\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size)\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
        "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    return mini_batches\n",
        "\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n",
        "\n",
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
        "    A1 = tf.nn.relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
        "    A2 = tf.nn.relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
        "\n",
        "    return Z3\n",
        "\n",
        "def predict(X, parameters):\n",
        "\n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "\n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "\n",
        "    x = tf.placeholder(\"float\", [12288, 1])\n",
        "\n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "\n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imcBCDzmsPBT",
        "outputId": "1960f75d-88fb-430a-858c-d098d73a2ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQkUkkzPSiUh",
        "outputId": "44a477f6-5336-4192-c42f-c01af92b995b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR1L2GYveWWq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0hoQtblQHOw",
        "outputId": "b60f3675-47e9-4dd2-f85e-56ac377c441b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_53), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_54), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2a_branch2a/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'bn2a_branch2a/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_55), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2a_branch2b/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'bn2a_branch2b/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_56), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2a_branch2c/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn2a_branch2c/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_57), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2a_branch1/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn2a_branch1/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_58), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2b_branch2a/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'bn2b_branch2a/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_59), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2b_branch2b/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'bn2b_branch2b/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_60), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2b_branch2c/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn2b_branch2c/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_61), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2c_branch2a/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'bn2c_branch2a/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_62), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2c_branch2b/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'bn2c_branch2b/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_63), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn2c_branch2c/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn2c_branch2c/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_64), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3a_branch2a/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3a_branch2a/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_65), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3a_branch2b/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3a_branch2b/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_66), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3a_branch2c/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn3a_branch2c/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_67), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3a_branch1/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn3a_branch1/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_68), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3b_branch2a/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3b_branch2a/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_69), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3b_branch2b/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3b_branch2b/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_70), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3b_branch2c/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn3b_branch2c/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_71), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3c_branch2a/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3c_branch2a/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_72), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3c_branch2b/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3c_branch2b/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_73), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3c_branch2c/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn3c_branch2c/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_74), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3d_branch2a/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3d_branch2a/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_75), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3d_branch2b/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'bn3d_branch2b/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_76), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn3d_branch2c/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn3d_branch2c/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_77), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4a_branch2a/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4a_branch2a/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_78), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4a_branch2b/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4a_branch2b/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_79), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4a_branch2c/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'bn4a_branch2c/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_80), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4a_branch1/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'bn4a_branch1/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_81), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4b_branch2a/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4b_branch2a/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_82), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4b_branch2b/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4b_branch2b/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_83), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4b_branch2c/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'bn4b_branch2c/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_84), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4c_branch2a/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4c_branch2a/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_85), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4c_branch2b/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4c_branch2b/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_86), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4c_branch2c/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'bn4c_branch2c/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_87), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4d_branch2a/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4d_branch2a/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_88), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4d_branch2b/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4d_branch2b/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_89), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4d_branch2c/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'bn4d_branch2c/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_90), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4e_branch2a/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4e_branch2a/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_91), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4e_branch2b/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4e_branch2b/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_92), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4e_branch2c/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'bn4e_branch2c/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_93), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4f_branch2a/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4f_branch2a/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_94), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4f_branch2b/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'bn4f_branch2b/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_95), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn4f_branch2c/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'bn4f_branch2c/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_96), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5a_branch2a/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn5a_branch2a/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_97), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5a_branch2b/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn5a_branch2b/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_98), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5a_branch2c/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'bn5a_branch2c/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_99), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5a_branch1/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'bn5a_branch1/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_100), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5b_branch2a/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn5b_branch2a/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_101), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5b_branch2b/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn5b_branch2b/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_102), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5b_branch2c/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'bn5b_branch2c/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_103), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5c_branch2a/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn5c_branch2a/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_104), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5c_branch2b/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'bn5c_branch2b/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_105), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'bn5c_branch2c/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'bn5c_branch2c/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.python.keras.models import Model, load_model\n",
        "\n",
        "#from tensorflow.python.keras.utils import plot_model\n",
        "#from utility_functions import *\n",
        "from tensorflow.python.keras.initializers import glorot_uniform\n",
        "#import tensorflow.python.keras.backend as K\n",
        "\n",
        "#K.set_image_data_format('channels_last')\n",
        "#K.set_learning_phase(1)\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \"\"\"\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters= F2,kernel_size= (f,f), strides=(1,1),padding='same',name =conv_name_base+'2b',kernel_initializer= glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3,name= bn_name_base +'2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(filters=F3,kernel_size= (1,1),strides=(1,1),padding='valid',name =conv_name_base+ '2c',kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3 ,name=bn_name_base +'2c')(X)\n",
        "\n",
        "    # Adding shortcut value to main path and passing it through a RELU activation\n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block\n",
        "    \"\"\"\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path\n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path\n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Shortcut path\n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Adding shortcut value to main path and passing it through a RELU activation\n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Implementation of the  ResNet50 architecture.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f = 3, filters = [128,128,512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128,128,512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128,128,512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128,128,512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f = 3, filters =  [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3,  [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3,  [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL\n",
        "    X = AveragePooling2D(pool_size=(2,2),name='avg_pool')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\n",
        "\n",
        "#tf.reset_default_graph()\n",
        "\n",
        "# model compiling\n",
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVFs6gg-mXZA",
        "outputId": "d2489296-2409-43b5-afd5-a0ab895114f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files extracted successfully:\n",
            "['Mild_Demented', 'Very_Mild_Demented', 'Non_Demented', 'Moderate_Demented']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/train_ds.zip'\n",
        "\n",
        "# Directory to extract the contents of the ZIP file\n",
        "extracted_dir_path = '/content/data_folder/train_ds'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir(extracted_dir_path)\n",
        "print(\"Files extracted successfully:\")\n",
        "print(extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsQsjcMTuSGO",
        "outputId": "6b5662b5-7f5a-4996-ea73-79c401df0973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files extracted successfully:\n",
            "['Mild_Demented', 'Very_Mild_Demented', 'Non_Demented', 'Moderate_Demented']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/test_ds.zip'\n",
        "\n",
        "# Directory to extract the contents of the ZIP file\n",
        "extracted_dir_path = '/content/data_folder/test_ds'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir(extracted_dir_path)\n",
        "print(\"Files extracted successfully:\")\n",
        "print(extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rIpED7Xv_lB",
        "outputId": "1bfc4980-a2a5-433d-eb37-0f76150a8c63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6400 files belonging to 4 classes.\n",
            "Using 5120 files for training.\n",
            "Found 6400 files belonging to 4 classes.\n",
            "Using 1280 files for validation.\n",
            "Found 6400 files belonging to 4 classes.\n",
            "(32, 64, 64, 3)\n",
            "[3 2 3 3 0 2 3 2 0 0 3 3 3 3 3 2 0 0 3 3 2 2 2 2 0 2 0 3 3 2 0 3]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "def load_dataset(train_dir, test_dir, image_size, batch_size):\n",
        "    train_ds = image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    val_ds = image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        validation_split=0.2,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    test_ds = image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        seed=123,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    classes = train_ds.class_names\n",
        "    return train_ds, val_ds, test_ds, classes\n",
        "\n",
        "# Define parameters\n",
        "train_dir = '/content/data_folder/train_ds'\n",
        "test_dir = '/content/data_folder/test_ds'\n",
        "image_size = (64, 64)\n",
        "batch_size = 32\n",
        "\n",
        "# Load dataset\n",
        "train_ds, val_ds, test_ds, classes = load_dataset(train_dir, test_dir, image_size, batch_size)\n",
        "\n",
        "# Example usage\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(images.shape)  # Shape of the batch of images\n",
        "    print(labels.numpy())  # Labels corresponding to the images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpIw59mAxhHt",
        "outputId": "31cb2c13-93b5-40ff-8deb-4f219b703b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (5120, 64, 64, 3)\n",
            "Y_train shape: (5120, 4)\n",
            "X_test shape: (6400, 64, 64, 3)\n",
            "Y_test shape: (6400, 4)\n",
            "Classes: ['Mild_Demented', 'Moderate_Demented', 'Non_Demented', 'Very_Mild_Demented']\n"
          ]
        }
      ],
      "source": [
        "def convert_to_one_hot(labels, num_classes):\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_classes)\n",
        "    return one_hot_labels.numpy()\n",
        "\n",
        "# Load and preprocess datasets\n",
        "# Assuming train_ds and test_ds are already loaded using image_dataset_from_directory\n",
        "# image_size and batch_size are defined earlier\n",
        "image_size = (64, 64)\n",
        "batch_size = 32\n",
        "\n",
        "# Example usage to get X_train, Y_train, X_test, Y_test, classes\n",
        "def preprocess_dataset(dataset):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_batch, label_batch in dataset:\n",
        "        images.append(image_batch.numpy())\n",
        "        labels.append(label_batch.numpy())\n",
        "    images = np.concatenate(images)\n",
        "    labels = np.concatenate(labels)\n",
        "    return images, labels\n",
        "\n",
        "X_train_orig, Y_train_orig = preprocess_dataset(train_ds)\n",
        "X_test_orig, Y_test_orig = preprocess_dataset(test_ds)\n",
        "classes = train_ds.class_names\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train_orig.astype('float32') / 255.0\n",
        "X_test = X_test_orig.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(classes)\n",
        "Y_train = convert_to_one_hot(Y_train_orig, num_classes)\n",
        "Y_test = convert_to_one_hot(Y_test_orig, num_classes)\n",
        "\n",
        "# Print shapes for verification\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"Y_train shape:\", Y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"Y_test shape:\", Y_test.shape)\n",
        "print(\"Classes:\", classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p2rm2t4zCdR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "# Define the model with adjusted input shape\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and fit the model as before\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5G3ZjcLyBUE",
        "outputId": "187449c8-329c-427b-d027-4e6eb08416f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "160/160 [==============================] - 6s 15ms/step - loss: 1.1850 - accuracy: 0.5613\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.4521 - accuracy: 0.8398\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.1849 - accuracy: 0.9486\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0784 - accuracy: 0.9842\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0234 - accuracy: 0.9984\n",
            "Epoch 6/20\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.0127 - accuracy: 0.9996\n",
            "Epoch 7/20\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 9.4462e-04 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 7.2731e-04 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 5.5209e-04 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 4.3741e-04 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 3.5136e-04 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 2.8652e-04 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 2.3345e-04 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 1.9247e-04 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 1.5982e-04 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 1.3531e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79d75e736020>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "# Fit the model\n",
        "model.fit(X_train, Y_train, epochs=20, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3PzLjrJT77M"
      },
      "outputs": [],
      "source": [
        "# train_dataset = train_dir\n",
        "# train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "# train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "\n",
        "# test_dataset = test_dir\n",
        "# test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "# test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
        "\n",
        "# classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "\n",
        "# train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "# test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc_0tGeKS-lI"
      },
      "outputs": [],
      "source": [
        "# X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = train_set_x_orig,train_set_y_orig,test_set_x_orig,test_set_y_orig,classes\n",
        "# X_train = X_train_orig/255.\n",
        "# X_test = X_test_orig/255.\n",
        "# Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "# Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w8-cDGFWUKF",
        "outputId": "75d3e754-2385-48c4-e624-0073af44ce61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9986\n",
            "Loss = 0.007747145369648933\n",
            "Test Accuracy = 0.9985937476158142\n"
          ]
        }
      ],
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "y_3L5WpMW3tW",
        "outputId": "19c812b6-9f04-43d1-a73b-82f4b19e9e9a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model,to_file='model_architecture.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmB1615TV-Ez",
        "outputId": "829862b3-93d2-4adc-85ad-6c89beecc25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 123008)            0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               15745152  \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15746564 (60.07 MB)\n",
            "Trainable params: 15746564 (60.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jTOEE3S3BJO"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save('/content/saved_model')  # Replace 'path_to_save_model.h5' with your desired save path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "lN9jHNN-1igp",
        "outputId": "250ef73f-bb3f-44c0-b4e6-cb112b7734b5"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at /content/saved_model",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-228dd5b8c13f>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Define target image size expected by your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/saved_model"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Function to preprocess uploaded image\n",
        "def preprocess_image(img_path, target_size):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model('/content/saved_model')\n",
        "\n",
        "# Define target image size expected by your model\n",
        "target_size = (64, 64)  # Adjust to match your model's input size\n",
        "\n",
        "# Example usage:\n",
        "uploaded_img_path = '/content/test_image_nondemented.jpg'\n",
        "preprocessed_img = preprocess_image(uploaded_img_path, target_size)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(preprocessed_img)\n",
        "\n",
        "# Interpret predictions\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class = classes[predicted_class_index]  # Assuming you have the class labels\n",
        "\n",
        "# Display prediction result\n",
        "print(f\"Predicted class: {predicted_class}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
